# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

raw_data_kobe:
  type: pandas.CSVDataSet
  filepath: data/01_raw/kobe_dataset.csv

data_filtered:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/data_filtered.parquet

data_conformed:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/data_conformed.parquet

base_train:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/base_train.parquet

base_test:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/base_test.parquet

preparacao_dados_metrics:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataSet

lr_model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/lr_model.pkl

pred_lr_model:
  type: pandas.ParquetDataSet
  filepath: data/07_model_output/pred_lr_model.parquet

modelo_reglog_metrics:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataSet

clf_model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/clf_model.pkl

pred_clf_model:
  type: pandas.ParquetDataSet
  filepath: data/07_model_output/pred_clf_model.parquet

modelo_clf_metrics:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataSet